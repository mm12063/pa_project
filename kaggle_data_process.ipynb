{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72ad6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d06c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_stocks = {\n",
    "    \"albemarle\": \"alb\",\n",
    "    \"ganfeng\": \"gnenf\",\n",
    "    \"livent\": \"lthm\",\n",
    "    \"lithium americas\": \"lac\",\n",
    "    \"lg chem\": \"051910\",\n",
    "    \"toshiba corp\": \"tosyy\",\n",
    "    \"panasonic\": \"pcrfy\",\n",
    "    \"samsung\": \"005930\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a34ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE_NAME = \"Kaggle\"\n",
    "DATA_DIR = os.path.join(\"NewsData\", \"Kaggle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "879022b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_timestamps = []\n",
    "all_headlines = []\n",
    "all_tickers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6eb9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(required_stocks, file_path, timestamp_header, headline_header, ticker_header=None, datetime_str_format=\"%Y-%m-%d %H:%M:%S%z\"):\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    print(\"initial size:\", dataset.shape[0])\n",
    "    \n",
    "    timestamps, headlines, tickers = [], [], [] \n",
    "    \n",
    "    def process_date_field(timestamp):\n",
    "        try:\n",
    "            timestamp = str(timestamp)\n",
    "            return datetime.strptime(timestamp, datetime_str_format)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    # Convert header and ticker to lowercase\n",
    "    dataset[headline_header] = dataset[headline_header].str.lower()\n",
    "    if ticker_header:\n",
    "        dataset[ticker_header] = dataset[ticker_header].str.lower()\n",
    "    \n",
    "    # Convert date fields to proper datetime object\n",
    "    dataset[timestamp_header] = dataset[timestamp_header].apply(process_date_field)\n",
    "    dataset = dataset[dataset[timestamp_header].notnull()]\n",
    "    print('after filtering date field:', dataset.shape[0])\n",
    "    \n",
    "    # Process dataset\n",
    "    for stock_name, stock_ticker in required_stocks.items():\n",
    "        if ticker_header:\n",
    "            filtered_df = dataset[\n",
    "                dataset[headline_header].str.contains(stock_name)\n",
    "                | dataset[headline_header].str.contains(\" \" + stock_ticker)\n",
    "                | dataset[headline_header].str.contains(stock_ticker + \" \")\n",
    "                | dataset[ticker_header].str.contains(stock_ticker)\n",
    "            ]\n",
    "        else:\n",
    "            filtered_df = dataset[\n",
    "                dataset[headline_header].str.contains(stock_name)\n",
    "                | dataset[headline_header].str.contains(\" \" + stock_ticker)\n",
    "                | dataset[headline_header].str.contains(stock_ticker + \" \")\n",
    "            ]\n",
    "        tickers.extend([stock_ticker]*filtered_df.shape[0])\n",
    "\n",
    "    timestamps = filtered_df[timestamp_header].tolist()\n",
    "    headlines = filtered_df[headline_header].tolist()\n",
    "    \n",
    "    print(\"final size:\", len(timestamps))\n",
    "    \n",
    "    return timestamps, headlines, tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94243af",
   "metadata": {},
   "source": [
    "### Process dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3587573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial size: 1400469\n",
      "after filtering date field: 1397891\n",
      "final size: 749\n"
     ]
    }
   ],
   "source": [
    "FILENAME = \"analyst_ratings_processed.csv\"\n",
    "timestamps, headlines, tickers = process_dataset(\n",
    "    required_stocks = required_stocks,\n",
    "    file_path = os.path.join(DATA_DIR, FILENAME),\n",
    "    timestamp_header = 'date',\n",
    "    headline_header = 'title',\n",
    "    ticker_header = 'stock',\n",
    "    datetime_str_format = '%Y-%m-%d %H:%M:%S%z'\n",
    ")\n",
    "all_timestamps.extend(timestamps)\n",
    "all_headlines.extend(headlines)\n",
    "all_tickers.extend(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609e4b5",
   "metadata": {},
   "source": [
    "### Process dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e2714c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial size: 1244184\n",
      "after filtering date field: 1244184\n",
      "final size: 93\n"
     ]
    }
   ],
   "source": [
    "FILENAME = \"abcnews-date-text.csv\"\n",
    "timestamps, headlines, tickers = process_dataset(\n",
    "    required_stocks = required_stocks,\n",
    "    file_path = os.path.join(DATA_DIR, FILENAME),\n",
    "    timestamp_header = 'publish_date',\n",
    "    headline_header = 'headline_text',\n",
    "    ticker_header = None,\n",
    "    datetime_str_format = '%Y%m%d'\n",
    ")\n",
    "all_timestamps.extend(timestamps)\n",
    "all_headlines.extend(headlines)\n",
    "all_tickers.extend(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf2597",
   "metadata": {},
   "source": [
    "### Process dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7230fc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial size: 73608\n",
      "after filtering date field: 73608\n",
      "final size: 22\n"
     ]
    }
   ],
   "source": [
    "FILENAME = \"RedditNews.csv\"\n",
    "timestamps, headlines, tickers = process_dataset(\n",
    "    required_stocks = required_stocks,\n",
    "    file_path = os.path.join(DATA_DIR, FILENAME),\n",
    "    timestamp_header = 'Date',\n",
    "    headline_header = 'News',\n",
    "    ticker_header = None,\n",
    "    datetime_str_format = '%Y-%m-%d'\n",
    ")\n",
    "all_timestamps.extend(timestamps)\n",
    "all_headlines.extend(headlines)\n",
    "all_tickers.extend(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303908c7",
   "metadata": {},
   "source": [
    "### Process dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8131105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial size: 221513\n",
      "after filtering date field: 221513\n",
      "final size: 459\n"
     ]
    }
   ],
   "source": [
    "FILENAME = \"us_equities_news_dataset.csv\"\n",
    "timestamps, headlines, tickers = process_dataset(\n",
    "    required_stocks = required_stocks,\n",
    "    file_path = os.path.join(DATA_DIR, FILENAME),\n",
    "    timestamp_header = 'release_date',\n",
    "    headline_header = 'title',\n",
    "    ticker_header = 'ticker',\n",
    "    datetime_str_format = '%Y-%m-%d'\n",
    ")\n",
    "all_timestamps.extend(timestamps)\n",
    "all_headlines.extend(headlines)\n",
    "all_tickers.extend(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4eede6",
   "metadata": {},
   "source": [
    "### Process dataset 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffaad3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial size: 1845559\n",
      "after filtering date field: 1845559\n",
      "final size: 747\n"
     ]
    }
   ],
   "source": [
    "FILENAME = \"raw_partner_headlines.csv\"\n",
    "timestamps, headlines, tickers = process_dataset(\n",
    "    required_stocks = required_stocks,\n",
    "    file_path = os.path.join(DATA_DIR, FILENAME),\n",
    "    timestamp_header = 'date',\n",
    "    headline_header = 'headline',\n",
    "    ticker_header = 'stock',\n",
    "    datetime_str_format = '%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "all_timestamps.extend(timestamps)\n",
    "all_headlines.extend(headlines)\n",
    "all_tickers.extend(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dcb053",
   "metadata": {},
   "source": [
    "### Create final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3584bcf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before deduplication (2070, 4)\n",
      "After deduplication (1489, 4)\n"
     ]
    }
   ],
   "source": [
    "TIMESTAMP_HEADER = 'date'\n",
    "HEADLINE_HEADER = 'headline'\n",
    "TICKER_HEADER = 'ticker'\n",
    "SOURCE_HEADER = 'source'\n",
    "INDEX_HEADER = 'idx'\n",
    "\n",
    "n = len(all_timestamps)\n",
    "str_timestamps = [timestamp.strftime('%Y-%m-%dT%H:%M:%SZ') for timestamp in all_timestamps]\n",
    "\n",
    "final_df = pd.DataFrame(\n",
    "    list(zip(\n",
    "        all_headlines,\n",
    "        all_timestamps,\n",
    "        all_tickers,\n",
    "        [DATA_SOURCE_NAME]*n)),\n",
    "    columns = [HEADLINE_HEADER, TIMESTAMP_HEADER, TICKER_HEADER, SOURCE_HEADER])\n",
    "\n",
    "# Remove duplicate rows\n",
    "print(\"Before deduplication\", final_df.shape)\n",
    "final_df = final_df.drop_duplicates()\n",
    "print(\"After deduplication\", final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81c476bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final_kaggle_data.csv', index_label = INDEX_HEADER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
